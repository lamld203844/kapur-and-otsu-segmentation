{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamld203844/kapur-and-otsu-segmentation/blob/main/gradio_GUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cSjGME8x4bda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232496d9-8f9b-4e5d-e76e-e186211d0b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kx4fHd0nj44D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc69af8-d54d-477f-fb4b-6231419bb307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install watermark\n",
        "!pip install -q watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oithBATekXAd",
        "outputId": "977d0d81-cff6-41d7-d8c8-0238c9fe7572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "gradio    : 4.15.0\n",
            "cv2       : 4.8.0\n",
            "numpy     : 1.23.5\n",
            "matplotlib: 3.7.1\n",
            "PIL       : 9.4.0\n",
            "scipy     : 1.11.4\n",
            "skimage   : 0.19.3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load watermark\n",
        "%load_ext watermark\n",
        "\n",
        "# Display the version of Python and Gradio\n",
        "%watermark -v -p gradio,cv2,numpy,matplotlib,PIL,scipy,skimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LcQ64BK9kmDs"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from scipy.ndimage import median_filter\n",
        "from skimage.filters import threshold_multiotsu\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_preprocessing(input_image, kernel_size):\n",
        "    \"\"\"\n",
        "    Preprocessing: average, median filter, and histogram equalization with size and\n",
        "    shape of the mask should be selected.((kernel_size = 3 by default))\n",
        "    \"\"\"\n",
        "    # Convert the input image to grayscale\n",
        "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # average filter\n",
        "    blurred_image = cv2.blur(gray_image, (kernel_size, kernel_size))\n",
        "\n",
        "    # median filter\n",
        "    median_filtered_image = median_filter(blurred_image, size=kernel_size)\n",
        "\n",
        "    # histogram equalizing\n",
        "    hist_equ_img = cv2.equalizeHist(gray_image)\n",
        "\n",
        "\n",
        "    return blurred_image, median_filtered_image, hist_equ_img"
      ],
      "metadata": {
        "id": "rGzKcuQkmBOM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UmSQ4z8XzizM"
      },
      "outputs": [],
      "source": [
        "def calculate_psnr(input_image):\n",
        "    # Convert the input image to grayscale\n",
        "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = np.mean((gray_image.astype(np.float64) / 255) ** 2)\n",
        "    if mse == 0:\n",
        "        return \"Same Image\"\n",
        "\n",
        "    # Calculate PSNR\n",
        "    PIXEL_MAX = 255.0\n",
        "    psnr = 20 * np.log10(PIXEL_MAX) - 10 * np.log10(mse)\n",
        "\n",
        "    return psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Q-abN4zDuFvs"
      },
      "outputs": [],
      "source": [
        "def kapur_segment(input_image):\n",
        "    # Convert the input image to grayscale\n",
        "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Normalize to 0 - 255\n",
        "    image = cv2.normalize(gray_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
        "\n",
        "    # Apply Kapur's method\n",
        "    thresholds = threshold_multiotsu(image)\n",
        "\n",
        "    # Apply the thresholds to get a segmented image\n",
        "    segmented_image = np.digitize(image, bins=thresholds)\n",
        "\n",
        "    return segmented_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fwU4u6VRnlno"
      },
      "outputs": [],
      "source": [
        "def otsu_segment(input_image):\n",
        "    # Convert the input image to grayscale\n",
        "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Normalize to 0 - 255\n",
        "    image = cv2.normalize(gray_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
        "\n",
        "    # Apply Otsu's thresholding\n",
        "    thresh = threshold_otsu(image)\n",
        "    binary = image > thresh\n",
        "\n",
        "    return binary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(pred, mask):\n",
        "    '''\n",
        "    Input: image and corresponding mask after normalization [0, 255] -> [0, 1], for example\n",
        "    Output: metrics\n",
        "    '''\n",
        "\n",
        "    # normalize eh_mask [0, 255] -> [0, 1]\n",
        "    norm_mask = np.where(mask, 1, 0)\n",
        "    # convert 3 channel to 1 channel\n",
        "    norm_mask_uint8 = norm_mask.astype(np.uint8)\n",
        "    mask = cv2.cvtColor(norm_mask_uint8, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # True positive\n",
        "    tp = np.sum((pred == 1) & (mask == 1))\n",
        "\n",
        "    # True negative\n",
        "    tn = np.sum((pred == 0) & (mask == 0))\n",
        "\n",
        "    # False positive\n",
        "    fp = np.sum((pred == 1) & (mask == 0))\n",
        "\n",
        "    # False negative\n",
        "    fn = np.sum((pred == 0) & (mask == 1))\n",
        "\n",
        "    # Sensitivity (also known as recall or true positive rate)\n",
        "    sensitivity = tp / (tp + fn)\n",
        "\n",
        "    # Specificity (also known as true negative rate)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    return sensitivity, specificity, accuracy"
      ],
      "metadata": {
        "id": "M8g7Gbem6H_5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LkBrFIEec6n4"
      },
      "outputs": [],
      "source": [
        "def main_function(img, kernel_sz, original_mask):\n",
        "\n",
        "    # basic img information\n",
        "    info = img.shape\n",
        "\n",
        "    # basic preprocessing\n",
        "    average_img, median_img, hist_equ_img = basic_preprocessing(img, kernel_sz)\n",
        "\n",
        "    # psnr value\n",
        "    psnr = calculate_psnr(img)\n",
        "\n",
        "    # segmentation Kapur method\n",
        "    kapur_seg_mask = kapur_segment(img)\n",
        "    kapur_img = ((kapur_seg_mask / kapur_seg_mask.max()) * 255).astype(np.uint8) # Map the segmented image from 0-255\n",
        "    # segmented_3_channel = cv2.cvtColor(segmented_image, cv2.COLOR_GRAY2BGR) # Convert the segmented image to a 3-channel image\n",
        "\n",
        "    # segmentation otsu method\n",
        "    otsu_seg_mask = otsu_segment(img)\n",
        "    otsu_img = cv2.cvtColor((otsu_seg_mask * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR) # Convert binary mask to a 3-channel image\n",
        "\n",
        "    # metrics calculation\n",
        "    sens, spec, acc = calculate_metrics(otsu_seg_mask, original_mask)\n",
        "    metric_overall = f'Otsu: {sens:.2f}, {spec:.2f}, {acc:.2f}'\n",
        "\n",
        "    return info, average_img, median_img, hist_equ_img, psnr, kapur_img, otsu_img, metric_overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "UfOhaJkZk0Pt",
        "outputId": "71faab28-1855-4f71-a3c2-cd856ffe5d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://6c5d287c018ce10e73.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6c5d287c018ce10e73.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://6c5d287c018ce10e73.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "inputs = [\n",
        "    gr.Image(type='numpy', label=\"Input original image\"),\n",
        "    gr.Number(label='kernel size (average and median filter only)', value=3),\n",
        "    gr.Image(type='numpy', label=\"Input original mask\"),\n",
        "]\n",
        "outputs = [gr.Textbox(label=\"Shape\"), # img info\n",
        "            gr.Image(label=\"avg filtering\"), # avg filtering\n",
        "            gr.Image(label=\"median filtering\"), # median filtering\n",
        "            gr.Image(label=\"histogram equalized img\"), # histogram equalizing\n",
        "            gr.Number(label=\"psnr value\"), # psnr value\n",
        "            gr.Image(label=\"kapur_segmentation\"), # segmentation Kapur method\n",
        "            gr.Image(label=\"otsu_segmentation\"), # segmentation Otsu method\n",
        "           gr.Textbox(label=\"Metrics accuracy, specificity, sensitivity respectively\"), # metrics\n",
        "        ]\n",
        "\n",
        "iface = gr.Interface(fn=main_function,\n",
        "                     inputs=inputs,\n",
        "                     outputs=outputs)\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Bu9U7HJohH",
        "outputId": "b8dba6d3-1312-4c2c-81a3-519e2bb50fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "iface.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrN6lAumsHpBoqJTMispEc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}